USE GRAPH simpleHealthDeux

CREATE QUERY cc_subquery (VERTEX source, SET<STRING> v_type, SET<STRING> e_type,
 INT num_vert, INT max_hops, BOOL wf = TRUE) FOR GRAPH simpleHealthDeux RETURNS (FLOAT) {
  /*
  Subquery returns closeness centrality for vertex source in graph with numVert vertices
  wf: Wasserman and Faust normalization factor for multi-component graphs 
  */
	SumAccum<INT> @@currDist, @@totalDist;
	SumAccum<INT> @@n;                       // vertices in this component
	OrAccum<BOOL> @visited;

	# Initialize: Set the input vertex source as the starting point
	Start = {source};
	Start = SELECT s FROM Start:s
			ACCUM s.@visited += true;

	# totalDist = sum(distance between vertex s and all connected neighbors)
	WHILE (Start.size() > 0) LIMIT max_hops DO    # explore up to (maxHops) hops FROM s
			@@currDist += 1;
			# Move FROM current start set to the neighboring set of (unvisited) vertices
			Start = SELECT t FROM Start:s -(e_type:e)-> v_type:t
					WHERE t.@visited == false AND t != s
					POST-ACCUM t.@visited += true;
							   @@totalDist += Start.size() * @@currDist;
			@@n += Start.size();
	END;

	IF @@totalDist > 0 THEN
			IF wf == TRUE THEN
					RETURN (@@n*1.0/(num_vert-1))*(@@n*1.0/@@totalDist);
			ELSE 
					RETURN (@@n*1.0/@@totalDist);
			END;
	ELSE
			RETURN (-1.0);
	END;
 }

CREATE QUERY closeness_cent(SET<STRING> v_type, SET<STRING> e_type, INT max_hops=10,
  INT top_k=100, BOOL wf = TRUE, BOOL print_accum = True, STRING result_attr = "",
  STRING file_path = "", BOOL display_edges = FALSE) FOR GRAPH simpleHealthDeux {
/*
  Compute Closeness Centrality for each VERTEX. Parameters:
  v_type: vertex types to traverse                 print_accum: print JSON output
  e_type: edge types to traverse                   result_attr: INT attr to store results to
  max_hops: look only this far from each vertex    file_path: file to write CSV output to
  output_limit: report only this many top scores   display_edges: output edges for visualization
  wf: Wasserman and Faust normalization factor for multi-component graphs 
  */
  
	TYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score> VertexScore;
	HeapAccum<VertexScore>(top_k, score DESC) @@topScores;
	SumAccum<FLOAT> @score;
	SetAccum<EDGE> @@edgeSet;
	FILE f (file_path);
	INT numVert;

# Compute closeness	
	Start = {v_type};
	numVert = Start.size();

	Start = SELECT s FROM Start:s
			# Calculate Closeness Centrality for each vertex
			POST-ACCUM s.@score = cc_subquery(s, v_type, e_type, numVert, max_hops, wf),
					IF result_attr != "" THEN s.setAttr(result_attr, s.@score) END,
					IF print_accum THEN @@topScores += VertexScore(s, s.@score) END,
					IF file_path != "" THEN f.println(s, s.@score) END;

#Output
	IF file_path != "" THEN
			f.println("Vertex_ID", "Closeness");
	END;

	IF print_accum THEN
		PRINT @@topScores AS top_scores;
		IF display_edges THEN
			PRINT Start[Start.@score];
			Start = SELECT s
			FROM Start:s -(e_type:e)->:t
				ACCUM @@edgeSet += e;
			PRINT @@edgeSet;
		END;
	END;
}

CREATE QUERY jaccard_nbor_ap_sub(VERTEX source, STRING e_type, STRING re_type, INT top_k, BOOL return_accum, STRING file_path, FILE f, STRING similarity_edge) FOR GRAPH simpleHealthDeux RETURNS (MapAccum<VERTEX, FLOAT>) {
/* This subquery calculates the Jaccard Similarity between a given vertex and every other vertex.
Jaccard similarity = intersection_size / (size_A + size_B - intersection_size)
*/
    
        MapAccum<VERTEX, FLOAT> @@topK_result;
        SumAccum<INT> @intersection_size, @@set_size_A, @set_size_B;
        SumAccum<FLOAT> @similarity;

        Start (ANY) = {source};
        Start = SELECT s
                FROM Start:s
                ACCUM @@set_size_A += s.outdegree(e_type);

        Subjects = SELECT t
                   FROM Start:s-(e_type:e)-:t;

        Others = SELECT t
                 FROM Subjects:s -(re_type:e)- :t
                 WHERE t != source 
                 ACCUM t.@intersection_size += 1, 
                       t.@set_size_B = t.outdegree(e_type)
                 POST-ACCUM t.@similarity = t.@intersection_size*1.0/(@@set_size_A + t.@set_size_B - t.@intersection_size)
                 ORDER BY t.@similarity DESC
                 LIMIT top_k;
        
        Others =  SELECT s
                  FROM Others: s
                  POST-ACCUM 
                      IF file_path != "" THEN f.println(source, s, s.@similarity) END,
                      IF return_accum THEN @@topK_result += (s -> s.@similarity) END;
      return @@topK_result;
}

CREATE QUERY jaccard_nbor_ap(STRING v_type, STRING e_type, STRING re_type, INT top_k, BOOL print_accum = TRUE, STRING similarity_edge = "", STRING file_path = "") FOR GRAPH simpleHealthDeux {
/* This query calls the subquery jaccard_nbor_ap_sub to get the similarity score of every pair of vertices.

  This query supports only taking in a single edge for the time being (8/13/2020).
*/
        MapAccum<VERTEX, FLOAT> @result;
        FILE f (file_path);
  
        start = {v_type};
        IF file_path != "" THEN
          f.println("Vertex1", "Vertex2", "Similarity");
        END;
        start = SELECT s
                FROM start:s
                POST-ACCUM 
                IF print_accum THEN
                  s.@result = jaccard_nbor_ap_sub(s, e_type, re_type, top_k, TRUE, file_path,f, similarity_edge)
                ELSE
                  jaccard_nbor_ap_sub(s, e_type, re_type, top_k, TRUE, file_path,f, similarity_edge)
                END;
  
        IF print_accum THEN
          PRINT start[start.@result];
        END;
}

CREATE QUERY louvain_parallel (SET<STRING> v_type, SET<STRING> e_type, STRING wt_attr,
  INT iter1=10, INT iter2=10, INT iter3=10, INT split=10, BOOL print_accum = TRUE,
  STRING result_attr = "", STRING file_path = "", BOOL comm_by_size = TRUE) FOR GRAPH simpleHealthDeux {
 /*
 * Louvain Method with Parallelism and Refinement
 * https://arxiv.org/pdf/1304.4453
 * The minimum label heuristics are implemented: https://doi.org/10.1016/j.parco.2015.03.003
 
Parameters:
 * v_type: vertex types to traverse        print_accum: print JSON
 * e_type: edge types to traverse          result_attr: INT attr to store results to
                                           file_path: file to write CSV output to
 * wt_attr: attribute for edge weights. The wt_attr data type is hardcoded to INT. FLOAT
  or DOUBLE can be supported by changing "INT" to "FLOAT"/"DOUBLE" (~10 instances) below. 
 * iter: There are three phases in the algorithm -- move, merge and refine. Their max number of iterations are set by iter1, iter2, iter3 respectively.
 * split: To save memory, split number is 10 by default. When the split number is larger, the query is closer to sequential Louvain Method, which is slower. When the split number is 1, the query is parallel, but requires more memory. 
 * comm_by_size: list community ids by size
*/
    
    TYPEDEF TUPLE <INT csize, INT number> ClusterNum;
    TYPEDEF TUPLE <VERTEX node, INT cid, FLOAT deltaQ> vDeltaQ;
    HeapAccum<vDeltaQ>(1, deltaQ DESC, cid ASC) @largestDeltaQ;   # if deltaQ is the same, select the one with mininal vid 
    MapAccum<INT, FLOAT> @@totIncidentCluster;   # sum of weight incident to clusters
    MapAccum<INT, INT> @@clusterSizes;           # size of a cluster
    MapAccum<INT, FLOAT> @weightToCluster; # weight from a vertex incident to that cluster
    SumAccum<FLOAT> @@totalWeight;   # total weight of all edges
    SumAccum<FLOAT> @weight;         # total weight incident to this vertex
    SumAccum<FLOAT> @cweight;        # total weight incident to this aggregate vertex
    SumAccum<INT> @uid;              # which vertex it belongs to
    SumAccum<INT> @cid;              # which cluster it belongs to
    SumAccum<INT> @vid;              # internal id
    SumAccum<FLOAT> @deltaQ;         # contribution to the modularity
    SumAccum<FLOAT> @@modularity;
    SumAccum<FLOAT> @@modularity2;
    MapAccum<INT, MapAccum<INT, FLOAT>> @@weightToClusterMap;   # calculate edges between communities 
    MapAccum<INT, SetAccum<INT>> @@moveComm; # map of communities that changed community id
    MapAccum<INT, MinAccum<VERTEX>> @@representMap;
    SetAccum<VERTEX> @@representSet;
    MapAccum<INT, FLOAT> @@vertexMap;
    MapAccum<INT, MapAccum<INT, FLOAT>> @@edgeMap;
    HeapAccum<ClusterNum>(100, csize ASC) @@clusterDist;
    MapAccum<INT, INT> @@clusterMap;
    MapAccum<INT, ListAccum<INT>> @@clusterMembers;
    FLOAT last_modularity = 0;
    FLOAT last_modularity2 = 0;
    INT iteration;
    INT Iter1; 
    FLOAT epsilon = 0.0001;
    INT iteration2;
    INT partitions;
    INT loop;
    INT debug = 0;  # debug: 0, no modularity info; 1, show debug log; 2, modularity for each iteration
    FILE f (file_path);
    
    partitions = split;
    CASE WHEN split < 1 THEN
            partitions = 1;
    END;
        
# Initialize: count edges and set a unique cluster ID for each vertex
    Start = {v_type};
    S = SELECT s 
        FROM Start:s -(e_type:e)-> :t
        ACCUM @@totalWeight += e.getAttr(wt_attr,"INT")*1.0,
            s.@weight += e.getAttr(wt_attr,"INT")*1.0
        POST-ACCUM s.@vid = getvid(s),
                   s.@uid = s.@vid,
                   s.@cid = s.@vid;  # Label each vertex with its own internal ID

# Special first iteration of Phase 1
    iteration = 1;
    S = SELECT s 
        FROM Start:s -(e_type:e)-> :t
        WHERE s.@cid > t.@cid
        ACCUM s.@largestDeltaQ += vDeltaQ(t, t.@cid, e.getAttr(wt_attr,"INT")*1.0 - 2 * s.@weight * s.@weight/ @@totalWeight) 
              # weightToCluster is just e.getAttr(wt_attr,"INT")*1.0
        POST-ACCUM INT bestCluster = s.@largestDeltaQ.top().cid,
                   IF s.@largestDeltaQ.size() > 0 and s.@largestDeltaQ.top().deltaQ > 0 and s.@cid != bestCluster THEN 
                           s.@cid = bestCluster
                   END,
                   s.@largestDeltaQ.clear();

    S = SELECT s
        FROM Start:s-(e_type:e)-:t
        WHERE s.@cid == t.@cid
        ACCUM @@modularity += e.getAttr(wt_attr,"INT")*1.0 - s.@weight * t.@weight / (@@totalWeight);

    @@modularity = @@modularity / @@totalWeight;                      
    PRINT iteration AS Phase1Iter, @@modularity;
    log(debug > 0, "[redrain]#move", iteration, @@modularity);
        
# Phase 1 -- Move
# For each vertex, calculate the change in modularity FROM adding it to each of the nearby clusters
# Add vertex to cluster with highest positive change in modularity
# Repeat the above until no vertices change cluster anymore
    S = SELECT s 
        FROM Start:s
        ACCUM @@totIncidentCluster += (s.@cid -> s.@weight); 
      
    iteration = 1;
    Iter1 = iter1 - 1;
      
    WHILE (iteration < 2 OR @@modularity - last_modularity > epsilon) LIMIT Iter1 DO
        iteration = iteration + 1;
        loop = 0;
        WHILE (loop < partitions) DO 
            S = SELECT s 
                FROM Start:s -(e_type:e)-> :t
                WHERE s.@uid % partitions == loop    # for different split
                    # At least one cluster not singlet(a cluster on its own). If both clusters are singlets, consider only when the label of target is smaller to avoid swap
                    AND (( abs(s.@weight - @@totIncidentCluster.get(s.@cid)) > epsilon   # s is not a singlet 
                    OR abs(t.@weight - @@totIncidentCluster.get(t.@cid)) > epsilon )     # or t is not a singlet
                    OR (abs(s.@weight - @@totIncidentCluster.get(s.@cid)) < epsilon      # s is a singlet 
                    AND abs(t.@weight - @@totIncidentCluster.get(t.@cid)) < epsilon      # t is also a singlet
                    AND s.@cid > t.@cid) )                                               # consider only when target label is smaller
                ACCUM s.@weightToCluster += (t.@cid -> e.getAttr(wt_attr,"INT")*1.0)
                POST-ACCUM INT bestCluster = s.@cid,
                    FLOAT maxDeltaQ = 0.0,
                    FLOAT deltaQ_new = 0.0,
                    FOREACH (cluster, weightToC) IN s.@weightToCluster DO   #would be better if this can be distributed
                        FLOAT incident = @@totIncidentCluster.get(cluster),
                        deltaQ_new = weightToC - 2 * incident * s.@weight/ @@totalWeight,
                        IF deltaQ_new > maxDeltaQ OR (abs(deltaQ_new - maxDeltaQ) < epsilon AND cluster < bestCluster) THEN   # when deltaQ_new is equal to maxDeltaQ, and the cluster label is smaller, also change 
                               maxDeltaQ = deltaQ_new,
                               bestCluster = cluster
                        END
                    END,
                    IF s.@cid != bestCluster THEN 
                        @@totIncidentCluster += (s.@cid -> (-1 * s.@weight)),
                        @@totIncidentCluster += (bestCluster -> s.@weight),
                        s.@cid = bestCluster
                    END,
                    s.@weightToCluster.clear();
            loop = loop + 1;
        END;
        last_modularity = @@modularity;
        @@modularity = 0;
        T1 = SELECT s
            FROM Start:s-(e_type:e)-:t
            WHERE s.@cid == t.@cid
            ACCUM @@modularity += e.getAttr(wt_attr,"INT")*1.0 - s.@weight * t.@weight / (@@totalWeight);
        @@modularity = @@modularity / @@totalWeight;                      
        PRINT iteration AS Phase1Iter, @@modularity;
        log(debug > 0, "[redrain]#move", iteration, @@modularity);
    END;

# Phase 2 --  Merge     
    iteration2 = 0;
    WHILE (iteration2 < 2 OR @@modularity2 - last_modularity2 > epsilon) LIMIT iter2 DO
        iteration2 = iteration2 + 1;
        Start = SELECT s
                FROM Start:s
                ACCUM s.@uid = s.@cid;      
        # Select the vertices with minimal internal id to represent the coarsened graph
        Start = SELECT s
                FROM Start:s 
                ACCUM @@representMap += (s.@cid -> s);

        FOREACH (key, value) IN @@representMap DO
                @@representSet += value;                       
        END;      
        represent = {@@representSet};
        @@representMap.clear();
        @@representSet.clear();
        log(debug > 0, "[redrain]#2_merge", represent.size()); #@@clusterSizes.size());

    # Get @cweight from totalIncident
        represent = SELECT s
                    FROM represent:s
                    ACCUM s.@cweight = @@totIncidentCluster.get(s.@uid),
                          @@clusterSizes += (s.@cid -> 1);

        log(debug > 1, "[redrain]#2_merge", @@weightToClusterMap.size());
        iteration = 0;
        last_modularity = 0;
        @@modularity = 0;

        WHILE (iteration < 2 OR @@modularity - last_modularity > epsilon) limit iter1 DO
            iteration = iteration + 1;

            # Calculate.getAttr(wt_attr,"INT")*1.0 incident from vertex to cluster in coarsened graph; change every interation
            S = SELECT s
                FROM Start:s -(e_type:e)-:t
                WHERE s.@cid != t.@cid AND @@totIncidentCluster.get(s.@uid) > 0 AND @@totIncidentCluster.get(t.@cid) > 0   #@@totIncidentCluster keeps changing, can be 0
                ACCUM @@weightToClusterMap += (s.@uid -> (t.@cid -> e.getAttr(wt_attr,"INT")*1.0));  # from s, incident to some clusters. Not consider the same cluster
            represent = SELECT s 
                FROM represent:s
                POST-ACCUM INT bestCluster = s.@cid,
                    FLOAT maxDeltaQ = 0.0,
                    FLOAT deltaQ_new = 0.0,
                    FOREACH (cluster, weightToC) IN @@weightToClusterMap.get(s.@uid) DO 
                        FLOAT incident = @@totIncidentCluster.get(cluster),
                        IF @@clusterSizes.get(s.@cid) == 1 AND @@clusterSizes.get(cluster) == 1 AND s.@cid < cluster THEN
                               CONTINUE
                        END,
                        deltaQ_new = weightToC - 2 * incident * s.@cweight/ @@totalWeight, #total weight should be the same
                        IF deltaQ_new > maxDeltaQ OR abs(deltaQ_new - maxDeltaQ) < epsilon AND cluster < bestCluster THEN      # new cluster is smaller then the current best cluster
                               maxDeltaQ = deltaQ_new,
                               bestCluster = cluster
                        END
                    END,
                    IF s.@cid != bestCluster THEN
                        @@totIncidentCluster += (s.@cid -> (-1 * s.@cweight)),
                        @@totIncidentCluster += (bestCluster -> s.@cweight),
                        @@moveComm += (s.@uid -> bestCluster),
                        @@clusterSizes += (s.@cid -> -1),
                        @@clusterSizes += (bestCluster -> 1),
                        s.@cid = bestCluster
                    END;
            log(debug > 1, "[redrain]#2_merge", @@weightToClusterMap.size()); 
            @@weightToClusterMap.clear();

            log(debug > 1, "[redrain]#2_move:", @@moveComm.size());
            # move nodes
            S = SELECT s
                FROM Start:s
                WHERE @@moveComm.containsKey(s.@uid)
                POST-ACCUM FOREACH v IN @@moveComm.get(s.@uid) DO
                                   s.@cid = v
                           END;
            @@moveComm.clear();

            last_modularity = @@modularity;           
            @@modularity = 0;

            S = SELECT s
                FROM Start:s-(e_type:e)-:t
                WHERE s.@cid == t.@cid
                ACCUM @@modularity += e.getAttr(wt_attr,"INT")*1.0 - s.@weight * t.@weight / (@@totalWeight);
                @@modularity = @@modularity / @@totalWeight;
                PRINT iteration AS Phase1Iter, @@modularity;
            log(debug > 0, "[redrain]#2_move", iteration, @@modularity);
        END;

        S = SELECT s
            FROM represent:s
            ACCUM s.@cweight = 0;
        @@clusterSizes.clear();

        last_modularity2 = @@modularity2;
        @@modularity2 = @@modularity;
        PRINT iteration2 AS Phase2Iter, @@modularity2;
        log(debug > 0, "[redrain]#2_merge", iteration2, @@modularity2);					  
    END;
        
        
# Phase 3 -- Refinement
    iteration = 0;
    @@modularity = 0;
    WHILE (iteration < 2 OR @@modularity - last_modularity > epsilon) LIMIT iter3 DO
        iteration = iteration + 1;
        S = SELECT s 
            FROM Start:s -(e_type:e)-> :t
            WHERE abs(s.@weight - @@totIncidentCluster.get(s.@cid)) > epsilon OR abs(t.@weight - @@totIncidentCluster.get(t.@cid)) > epsilon OR (abs(s.@weight - @@totIncidentCluster.get(s.@cid)) < epsilon AND abs(t.@weight - @@totIncidentCluster.get(t.@cid)) < epsilon AND s.@cid > t.@cid)   # at least one cluster not only itself, or use smaller label
            ACCUM s.@weightToCluster += (t.@cid -> e.getAttr(wt_attr,"INT")*1.0)
            POST-ACCUM
                INT bestCluster = s.@cid,
                FLOAT maxDeltaQ = 0.0,
                FLOAT deltaQ_new = 0.0,
                FOREACH (cluster, weightToC) IN s.@weightToCluster DO   #would be better if this can be distributed
                    FLOAT incident = @@totIncidentCluster.get(cluster),
                    deltaQ_new = weightToC - 2 * incident * s.@weight/ @@totalWeight,
                    IF deltaQ_new > maxDeltaQ OR (abs(deltaQ_new - maxDeltaQ) < epsilon AND cluster < bestCluster) THEN   # when deltaQ_new is equal to maxDeltaQ, and the cluster label is smaller, also change 
                    maxDeltaQ = deltaQ_new,
                    bestCluster = cluster
                    END
                END,
                IF s.@cid != bestCluster THEN 
                    @@totIncidentCluster += (s.@cid -> (-1 * s.@weight)),
                    @@totIncidentCluster += (bestCluster -> s.@weight),
                    s.@cid = bestCluster
                END,
                s.@weightToCluster.clear();

        last_modularity = @@modularity;
        @@modularity = 0;
        T1 = SELECT s
             FROM Start:s-(e_type:e)-:t
             WHERE s.@cid == t.@cid
             ACCUM @@modularity += e.getAttr(wt_attr,"INT")*1.0 - s.@weight * t.@weight / (@@totalWeight);
        @@modularity = @@modularity / @@totalWeight;                      
        PRINT iteration AS Phase3Iter, @@modularity;
        log(debug > 0, "[redrain]#refine", iteration, @@modularity);
    END;
	
	Start = SELECT s FROM Start:s
	    POST-ACCUM
	        IF result_attr != "" THEN s.setAttr(result_attr, s.@cid) END,
	        IF file_path != "" THEN f.println(s, s.@cid) END
	    ;
	IF print_accum THEN
	    PRINT Start[Start.@cid];
	END;
    
    Start = {v_type};
    Start = SELECT s FROM Start:s
        POST-ACCUM @@clusterSizes += (s.@cid -> 1)
        ;
    log(TRUE, @@clusterSizes.size());

    IF comm_by_size THEN
        FOREACH (cluster, csize) IN @@clusterSizes DO
                @@clusterMembers += (csize -> cluster);
        END;
        PRINT @@clusterMembers;
    END;
}

CREATE QUERY pageRank_wt (STRING v_type, STRING e_type, STRING wt_attr,
 FLOAT max_change=0.001, INT max_iter=25, FLOAT damping=0.85, INT top_k = 100,
 BOOL print_accum = TRUE, STRING result_attr =  "", STRING file_path = "",
 BOOL display_edges = FALSE) FOR GRAPH simpleHealthDeux{
/*
 Compute the pageRank score for each vertex in the GRAPH
 In each iteration, compute a score for each vertex:
     score = (1-damping) + damping*sum(received scores FROM its neighbors).
 The pageRank algorithm stops when either of the following is true:
 a) it reaches max_iter iterations;
 b) the max score change for any vertex compared to the last iteration <= max_change.
 v_type: vertex types to traverse          print_accum: print JSON output
 e_type: edge types to traverse            result_attr: INT attr to store results to
 wt_attr: attribute for edge weights
 max_iter: max #iterations                 file_path: file to write CSV output to
 top_k: #top scores to output              display_edges: output edges for visualization
 max_change: max allowed change between iterations to achieve convergence
 damping: importance of traversal vs. random teleport

 This query supports only taking in a single edge for the time being (8/13/2020).
*/
	TYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score> Vertex_Score;
	HeapAccum<Vertex_Score>(top_k, score DESC) @@topScores;
	MaxAccum<FLOAT> @@max_diff = 9999;    # max score change in an iteration
	SumAccum<FLOAT> @recvd_score = 0; # sum of scores each vertex receives FROM neighbors
	SumAccum<FLOAT> @score = 1;           # initial score for every vertex is 1.
	SetAccum<EDGE> @@edgeSet;             # list of all edges, if display is needed
	SumAccum<FLOAT> @total_wt;
	FILE f (file_path);

	Start = {v_type};
 # Calculate the total weight for each vertex
	Start = SELECT s                
            FROM Start:s -(e_type:e) -> v_type:t
            ACCUM s.@total_wt += e.getAttr(wt_attr, "FLOAT"); 
            
# PageRank iterations	
                     # Start with all vertices of specified type(s)
	WHILE @@max_diff > max_change LIMIT max_iter DO
			@@max_diff = 0;
			V = SELECT s
				FROM Start:s -(e_type:e)-> v_type:t
				ACCUM t.@recvd_score += s.@score * e.getAttr(wt_attr, "FLOAT")/s.@total_wt
				POST-ACCUM s.@score = (1.0-damping) + damping * s.@recvd_score,
						   s.@recvd_score = 0,
						   @@max_diff += abs(s.@score - s.@score');
	END; # END WHILE loop

# Output
	IF file_path != "" THEN
	  f.println("Vertex_ID", "PageRank");
	END;

	V = SELECT s FROM Start:s
		POST-ACCUM 
			IF result_attr != "" THEN s.setAttr(result_attr, s.@score) END,
			IF file_path != "" THEN f.println(s, s.@score) END,
			IF print_accum THEN @@topScores += Vertex_Score(s, s.@score) END;

	IF print_accum THEN
		PRINT @@topScores;
		IF display_edges THEN
			PRINT Start[Start.@score];
			Start = SELECT s
					FROM Start:s -(e_type:e)-> v_type:t
					ACCUM @@edgeSet += e;
		   PRINT @@edgeSet;
		END;
	END;
}

CREATE QUERY pageRank (STRING v_type, STRING e_type,
 FLOAT max_change=0.001, INT max_iter=25, FLOAT damping=0.85, INT top_k = 100,
 BOOL print_accum = TRUE, STRING result_attr =  "", STRING file_path = "",
 BOOL display_edges = FALSE) FOR GRAPH simpleHealthDeux {
/*
 Compute the pageRank score for each vertex in the GRAPH
 In each iteration, compute a score for each vertex:
     score = (1-damping) + damping*sum(received scores FROM its neighbors).
 The pageRank algorithm stops when either of the following is true:
 a) it reaches max_iter iterations;
 b) the max score change for any vertex compared to the last iteration <= max_change.
 v_type: vertex types to traverse          print_accum: print JSON output
 e_type: edge types to traverse            result_attr: INT attr to store results to
 max_iter; max #iterations                 file_path: file to write CSV output to
 top_k: #top scores to output              display_edges: output edges for visualization
 max_change: max allowed change between iterations to achieve convergence
 damping: importance of traversal vs. random teleport

 This query supports only taking in a single edge for the time being (8/13/2020).
*/
	TYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score> Vertex_Score;
	HeapAccum<Vertex_Score>(top_k, score DESC) @@topScores;
	MaxAccum<FLOAT> @@max_diff = 9999;    # max score change in an iteration
	SumAccum<FLOAT> @recvd_score = 0; # sum of scores each vertex receives FROM neighbors
	SumAccum<FLOAT> @score = 1;           # initial score for every vertex is 1.
	SetAccum<EDGE> @@edgeSet;             # list of all edges, if display is needed
	FILE f (file_path);

# PageRank iterations	
	Start = {v_type};                     # Start with all vertices of specified type(s)
	WHILE @@max_diff > max_change LIMIT max_iter DO
			@@max_diff = 0;
			V = SELECT s
				FROM Start:s -(e_type:e)-> v_type:t
				ACCUM t.@recvd_score += s.@score/(s.outdegree(e_type)) 
				POST-ACCUM s.@score = (1.0-damping) + damping * s.@recvd_score,
						   s.@recvd_score = 0,
						   @@max_diff += abs(s.@score - s.@score');
	END; # END WHILE loop

# Output
	IF file_path != "" THEN
	  f.println("Vertex_ID", "PageRank");
	END;

	V = SELECT s FROM Start:s
		POST-ACCUM 
			IF result_attr != "" THEN s.setAttr(result_attr, s.@score) END,
			IF file_path != "" THEN f.println(s, s.@score) END,
			IF print_accum THEN @@topScores += Vertex_Score(s, s.@score) END;

	IF print_accum THEN
		PRINT @@topScores;
		IF display_edges THEN
			PRINT Start[Start.@score];
			Start = SELECT s
					FROM Start:s -(e_type:e)-> v_type:t
					ACCUM @@edgeSet += e;
		   PRINT @@edgeSet;
		END;
	END;
}

CREATE QUERY shortest_ss_no_wt (VERTEX source, SET<STRING> v_type, SET<STRING> e_type, 
  INT output_limit = -1, BOOL print_accum =TRUE, STRING result_attr ="", STRING file_path ="",
  BOOL display_edges =FALSE) FOR GRAPH simpleHealthDeux {
/*
Single-source shortest path algorithm, with unweighted edges.
From the source vertex, finds the unweighted shortest path (number of hops, INT value)
 source: start vertex                         print_accum: print JSON output
 v_type: vertex types to traverse             result_attr: INT attr to store results to
 e_type: edge types to traverse               file_path: file to write CSV output to
 output_limit: max #vertices to output        display_edges: output edges for visualization
*/

	FILE f(file_path);
	MinAccum<INT> @dis;
	OrAccum @visited;
	ListAccum<VERTEX> @path;
	SetAccum<EDGE> @@edgeSet;

	##### Initialization  #####
	Source = {source};
	Source = SELECT s 
			 FROM Source:s
			 ACCUM s.@visited += true, 
				   s.@dis = 0,
				   s.@path = s; 
	ResultSet = {source};

	##### Calculate distances and paths #####
	WHILE(Source.size()>0) DO
		Source = SELECT t
				 FROM Source:s -(e_type:e)-> v_type:t
				 WHERE t.@visited == false
				 ACCUM t.@dis += s.@dis + 1,
					   t.@path = s.@path + [t],
					   t.@visited += true
				ORDER BY getvid(t);
		ResultSet = ResultSet UNION Source;
	END;

	IF file_path != "" THEN
		f.println("Vertex_ID","Distance","Shortest_Path");
	END;

	ResultSet = SELECT s FROM ResultSet:s 
				POST-ACCUM 
					IF result_attr != "" THEN s.setAttr(result_attr, s.@dis) END,
					IF file_path != "" THEN f.println(s, s.@dis, s.@path) END
	;


	IF print_accum THEN
    IF output_limit >= 0 THEN
        ResultSet = SELECT s FROM ResultSet:s LIMIT output_limit;
    END;
		PRINT ResultSet[ResultSet.@dis, ResultSet.@path];
		IF display_edges THEN

			ResultSet = SELECT s FROM ResultSet:s -(e_type:e)-> v_type:t
			ACCUM @@edgeSet += e;
			PRINT @@edgeSet;
		END;
	END;
}

INSTALL QUERY ALL
